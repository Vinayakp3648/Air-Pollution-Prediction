{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4uQZLB6K1AkI0X93nBdqm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vinayakp3648/Air-Pollution-Prediction/blob/main/pollution%20air.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FCmzSC3NSnzr"
      },
      "outputs": [],
      "source": [
        "\n",
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "#To predict quality of Air Pollution\n",
        "#Author: Akshay Mattoo\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "get_ipython().run_line_magic('matplotlib', 'inline')\n",
        "\n",
        "df_train = pd.read_csv('/content/Train.csv')\n",
        "df_test  = pd.read_csv('/content/Test.csv')\n",
        "\n",
        "\n",
        "#Store the training data\n",
        "train_data = df_train.values\n",
        "\n",
        "Y_train = train_data [1:,-1]\n",
        "X_train = train_data [1:,:-1]\n",
        "\n",
        "X_train = np.mat(X_train)\n",
        "Y_train = np.mat(Y_train)\n",
        "Y_train = Y_train.reshape ((1599, 1))\n",
        "\n",
        "\n",
        "#Obtain the weight matrix\n",
        "def getWeight (query_point, X_train, tau):\n",
        "    M = X_train.shape[0]\n",
        "    W = np.mat(np.eye(M))\n",
        "\n",
        "    for i in range (M):\n",
        "        xi = X_train[i]\n",
        "        x = query_point\n",
        "        W[i,i] = np.exp((np.sum(xi-x) ** 2)/(-2*tau*tau)) #Compute the weight for each query point and store it in the diagonal Weight matrix\n",
        "\n",
        "    return W\n",
        "\n",
        "\n",
        "\n",
        "X_test = df_test.values\n",
        "X_test = X_test[0:,:]\n",
        "X_test = np.mat(X_test)\n",
        "X_test.size\n",
        "\n",
        "\n",
        "def predict (X_train, Y_train, query_point, tau):\n",
        "    ones = np.ones ((X_train.shape[0], 1))\n",
        "    X_ = np.hstack((X_train, ones))\n",
        "\n",
        "    qx = np.hstack((query_point, np.ones((query_point.shape[0], 1))))\n",
        "\n",
        "    W = getWeight(qx, X_, tau)\n",
        "\n",
        "    theta = np.linalg.pinv(X_.T*(W*X_))*(X_.T*(W*Y_train))\n",
        "    pred = np.dot(qx, theta)\n",
        "    return theta, pred\n",
        "\n",
        "\n",
        "with open (\"result.csv\",'w') as f:\n",
        "    f.write(\"Id,target \\n\")\n",
        "    for i in range(0, 400, 1):\n",
        "        theta, pred = predict (X_train, Y_train, X_test[i], 0.1)\n",
        "        f.write(str(i))\n",
        "        f.write(\",\")\n",
        "        f.write(str(pred)[2:-2])\n",
        "        f.write(\"\\n\")\n"
      ]
    }
  ]
}